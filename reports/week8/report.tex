\documentclass[a4paper,10pt,twoside]{IEEEtran}

\usepackage{abstract}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{placeins}
\usepackage{hyperref}
\usepackage{pdfpages}
\usepackage{fullpage}
\usepackage[bf]{caption}
\usepackage[english]{babel}
\usepackage{verbatim}
\usepackage{cite}
\usepackage{wrapfig}
\usepackage[marginpar]{todo}
\usepackage{paralist}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{fancyhdr}

\usepackage{tikz}
\usetikzlibrary{calc,intersections}
\usepackage{amssymb}

\hypersetup{
    colorlinks,
    pdftitle={Final Report Option 1 IN4254 Smart Phone Sensing},
    pdfauthor={in4254-dhoepelman-mprovokluit},
}

\setlength{\parindent}{0pt}
\setlength{\parskip}{2ex}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\newcommand{\axis}[1]{$#1$\nobreakdash-axis}
\newcommand{\plane}[2]{$#1#2$\nobreakdash-plane}

\title{\huge{\textbf{Final Report Option 1}\\IN4254 Smart Phone Sensing}}
\date{\today}
\author{David Hoepelman (1521969) \and Mark Provo Kluit (1263099)}

\setlength{\headheight}{15pt}
\addtolength{\headsep}{15pt} % no love between header and main text
%\addtolength{\textheight}{-20pt} % more space between text and empty footer

\pagestyle{fancy}
%\renewcommand{\chaptermark}[1]{\markboth{Chapter\ \thechapter\ #1}{}}
%\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}{}}
 
\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[RE]{\textit{\nouppercase{\leftmark}}}
\fancyhead[LO]{\textit{\nouppercase{\rightmark}}}
 
\fancypagestyle{plain}{ %
\fancyhf{} % remove everything
\renewcommand{\headrulewidth}{0pt} % remove lines as well
\renewcommand{\footrulewidth}{0pt}}

\begin{document}

\maketitle

\newpage
\pagenumbering{roman}

%% 1: up to sections; 2: up to subsections
%\setcounter{tocdepth}{1}
%\tableofcontents

\newpage
\pagenumbering{arabic}

\section{Basic Information}
\label{sec:basic-information}
The two phones we used are the Samsung Galaxy~S (Mark) running on Android~2.3.3 and LG Nexus~4 (David) running on Android~4.4.3. \autoref{tab:used-libraries} shows the libraries that are used in the application. The ORMLite library is used to store and retrieve data from an SQLite database. The Apache Commons Math library is used for computing the Euclidean distance and to compute various statistics. Guava provides various utility functions used by the application.

\begin{table}[ht]
\centering
\caption{Libraries used by the Android app.}
\begin{tabular}{ll}
\toprule
Library & Version\\
\midrule
ORMLite & 4.48\\
Guava & 17\\
Apache Commons Math & 3.2\\
\bottomrule
\end{tabular}
\label{tab:used-libraries}
\end{table}

\section{Activity Monitoring (1 page)}
\label{sec:activity-monitoring}
We define four activities that need to be recognized by the application: sitting, walking, running, and going up and down in the elevator. The application measures the three axes (x, y, and z) of the accelerometer every 20~ms and groups them together in windows of 240 samples. These windows are also used by the steps counter for updating the movement model during localization. For each window several features are computed:

\begin{itemize}
\item Mean $\mu$ for each axis: $\mu_x$, $\mu_y$, and $\mu_z$
\item Standard deviation $\sigma$ for each axis: $\sigma_x$, $\sigma_y$, and $\sigma_z$
\item Correlation between each two axes:  $\text{Corr(}x,y{)}$, $\text{Corr(}y,z{)}$, and $\text{Corr(}z,x{)}$
\end{itemize}

To classify the windows a k-NN classifier was constructed. The classifier uses the Euclidean distance for which we used the Apache Commons Math library. For $n$ measured windows during the training, the classifier tests a measurement using $\sqrt{n}$ neighbors with a 50-50 random tie breaker. We have collected about 20 training measurement windows of each activity type and 20 testing measurement windows of each activity type. The resulting confusion matrix is shown in \autoref{tab:confusion-matrix}.

\begin{table}[ht]
\centering
\caption{Confusion matrix of our classifier.}
\begin{tabular}{lrrrr}
\toprule
& Sitting & Walking & Running & Jumping  \\
\midrule
Sitting & 90 \% &  10 \% &       &       \\
Walking &       & 100 \% &       &       \\
Running &       &  15 \% & 70 \% & 15 \% \\
Jumping &       &        & 15 \% & 85 \% \\
\bottomrule
\end{tabular}
\label{tab:confusion-matrix}
 \end{table}

The confusion matrix shows that the classifier is able to correctly classify the various activities most of the time. When running or jumping it sometimes incorrectly classifies the activity as jumping and running, respectively.

\section{Localization (3 pages)}
\label{sec:localization}

\subsection{Data collection}
\label{sec:loc-localization-method}
For each of the available 17 rooms on the 9$^{\text{th}}$ floor of EWI, we have collected Wi-Fi signal strengths of all the access points our mobile phone could find. The signals collected for training the locator have been collected using the LG Nexus~4 smart phone, since it has the capability to measure 5~GHz signals as well as the 2.4~GHz signals (the Samsung Galaxy~S can only detect 2.4~GHz signals) and overall has a much better reception of the signals. This shows that in order for the locator to work reliably, the user needs to have a decent modern smart phone.
We have drawn a rough not-to-scale map of the rooms, and show it to the user as part of our GUI. See \autoref{fig:screenshot}.

In total we have collected \textbf{3300} scans on three different days.
A scan list contains the \emph{access points} (AP's) that were detected as a list of $signal = (BSSID, SSID, level)$ tuples where $level$ is expressed in dBm with a range of $[-30,-100]$.
Both 2.4~GHz and 5~GHz access points were detected and stored in the database.
Most rooms have either 180 or 240 scans, depending on which days they were accessible.
The collected scans inside a room were evenly divided among the room area.

On average each scan contains 20~$BSSID$'s, although the number varies per room.
We did a fixed number of scans per room on every day, but this does not translate well into a sampling time per cell.
The reason for this is that the time required to perform a signal scan
differs greatly depending on the number of AP's that are visible in a room.

\subsection{Localization method}
\label{sec:loc-data}

We chose to use \textbf{Bayesian Filters} for our localization method. We identify an AP using the $BSSID$, which is guaranteed globally unique.

For our calculations we group the training data on $BSSID$ and $Room$ and calculate the normal distribution $N_{BSSID,Room}(\mu_{BSSID,Room}, \sigma^2_{BSSID,Room})$ using the measured signal strengths.

We provide an example with 2 BSSID's and two Rooms, pulled from our collected data.
You can see the histogram of the 4 $(BSSID, Room)$ combination in \autoref{fig:histogram}.
Their respective normal distributions can be seen in \autoref{fig:distribution}.
 You can clearly see that there is a difference in the distributions of the received signal strengths, even though these rooms are next to each other and not separated by a wall.
 This gives high hopes for the effectiveness of the Bayesian filter approach

Signals whose $SSID$ is either ``TUvisitor'', ``tudelft-dastud'',
or ``Conferentie-TUD'' are ignored.
This is because most access points of the TU Delft sent out four different $SSID$'s (the fourth is ``eduroam'') with different $BSSID$'s.
As these signals come from the same physical location and have the same
frequency (and probably the same radio's) we did not think they would add more
information, and at worst might make our results less accurate (by processing
essentially the same signal 4 times, thus biasing the results heavily on those AP's).

For localization we express the location as a probability vector $\mathbf{loc}$, with $\mathbf{loc}_{r}$ being the probability that we are in room $r$. 
We initially start with the \emph{initial belief} where all locations have the same probability $\mathbf{loc}_r = \frac{1}{|\mathbf{loc}|}$.
We then do a WiFi scan which gives a list of signals.
We sort this list on level, with strongest level first.
As long as the largest probability is under a threshold $0.95$ we then iterate the list, while adjusting the location each iteration.
The location is adjusted by getting for each room the chance of that signal level and multiplying it with the existing probability. After each iteration we normalize $\mathbf{loc}$ by making it sum to 1.
\\
\begin{algorithmic}
	\State $scan \gets \text{list of } (BSSID, SSID, level) \text{ sorted on }level$
	\While {$\max\left(\mathbf{loc}\right) < 0.95$}
		\State $signal \gets \text{next}\left(scan\right)$
		\ForAll{$Room$}
			\State $p \gets N_{BSSID,Room}(level-0.5,level+0.5)$
			\State $\mathbf{loc}_{Room} \gets \mathbf{loc}_{Room} \cdot p $
		\EndFor
		\State $\text{normalize}\left(\mathbf{loc}\right)$
	\EndWhile
\end{algorithmic}

$\mathbf{loc}$ is retained between scans until the locator is reset by the user to its initial belief.

\subsubsection{Number of access points}
\label{subsec:loc-numap}

While we achieved a pretty good accuracy with pure Bayesian filters (see performance evaluation section), we had trouble in the \emph{Coffee} room which did not have a large number of APs visible, thus providing too little information for our Bayesian filter.
We solved this problem by constructing $N_{\#,Room}$ distributions.
This distribution gives the probability for number of AP's in a scan based on the $\mu$ and $\sigma$ of the number of AP's per room in the training data.

As can be seen from the average number of APs visible in a room in \autoref{fig:graph-numberAPperRoom} this varies between rooms, and thus can provide extra information for our localization.

We append the following to the previous algorithm:
\\
\begin{algorithmic}
	\If {$\max\left(\mathbf{loc}\right) < 0.95$}
		\ForAll{$Room$}
			\State $p \gets N_{\#,Room}(|scan|-0.5,|scan|+0.5)$
			\State $\mathbf{loc}_{Room} \gets \mathbf{loc}_{Room} \cdot p $
		\EndFor
		\State $\text{normalize}\left(\mathbf{loc}\right)$
	\EndIf
\end{algorithmic}

\subsection{Movement Model}
\label{sec:loc-movement-model}
For updating the probabilities using a movement model, a steps counter was implemented. The steps counter trains the k-NN classifier using the features of the windows collected during the activity training. When the steps counter is active, it collects one window containing 240 samples and then calls the classifier to find out whether the user is walking or not. If the classifier classifies the window as walking, then the steps counter increases the number of counted steps.

Every time the the steps counter classifies the window as not-sitting, it counts this as the user has takes four steps. It then invokes the Bayesian locator to update the probabilities. The locator constructs a uniform distribution of between $0.5s$ and $1.2s$ meters, where $s$ is the number of steps. Due to the size of the rooms ($7.2$~meters) and the upper bound on the number of steps that the locator receives (4 steps), the probabilities are such that the current room and its adjacent rooms have a zero or non-zero probability, but the $2^{nd}$ level of adjacent rooms always have a zero probability. Taking advantage of this upper bound simplifies the code quite a bit.

\subsection{Performance evaluation}
\label{sec:loc-evaluation}

For our performance evaluation we used off-line processing. We divided the scans of our training data into 10 random partitions, and tested every partition while using the other partitions as training data for the locator.

Using this method we achieved an accuracy of \textbf{83\%} (2731 correct out of 3300).
While analyzing the data we saw that a lot of the misclassified scans occurred in the Coffee room,
where a scan usually contains at most three signals. This is not enough for the Bayesian filter.

To alleviate this problem we altered our code to take the number of visible signals into account.
This improved our accuracy to \textbf{89\%} (2945 of 3300).
The technical implementation for this is specified in section \ref{subsec:loc-numap}.
If we mark adjacent rooms as correct too, which is not unreasonable as some training scans were taken on the border between rooms, the accuracy increases to \textbf{95\%} (3132 of 3300).

In \autoref{fig:iterations-needed} the number of iterations that is needed for a certain (95\% certainty) localization is visible.
We see that almost all signals are used, and only after about 23 signals the information is not useful anymore.
We do note that this is purely for the 95\% certainty threshold.
We have not tested how less data or a lower iterations cap would influence the number of correct (but less certain) localizations.

\section{Cloud Computing (1 page)}
\label{sec:cloud-computing}
For cloud computing we decided to implement the ability to spy on the detected localization using a second phone. The ``NSA fragment'' allows another user to see the location of the first user on a map. More precisely, the GUI shows a map -- identical to the map shown in the localization testing GUI -- which duplicates the probabilities shown on the screen of the phone of the first user.

Initially the Google Cloud Messaging (GCM) service was used, but this proved to be quite slow. Because of this reason, we switched to using using a simple direct TCP socket connection. When the user enters an IP address in the GUI of \textsc{LocatorNSAFragment}, the application creates a new \textsc{Thread} which creates a \textsc{ObjectInputStream} from a client socket. It then calls the \textsc{readObject()} method on this object to receive \textsc{Map<Room, Double>} and if Java can successfully deserialize the object, it will use the received probabilities to update the map shown on the screen.

Response time was shown to be much faster; sending the location probabilities from the LG Nexus 4 to the Samsung Galaxy S over the eduroam network takes on average about $1.6$~seconds. Furthermore, the approach using TCP sockets was found to be easier to implement than GCM.

\section{Challenges \& Innovation (0.25 pages)}
\label{sec:innovation}
\subsection{Activity Monitoring Difficulties}
One of the challenges of activity monitoring was selecting the appropriate features and the size of the feature vectors.
We noticed that the correlation features (visually) do not seem to have clear clusters.

TODO Mahalanobis distance versus Euclidean
TODO Correlation features useful?

\subsection{Localization Difficulties}

We did not have major difficulties with implementing the localization.
We were actually surprised at the relative easy and relative good accuracy our Bayesian filter provided.

We did have a lot of problems with implementing our movement model, but did not address them in this report as we were told the movement model should not be in this report.

\autoref{fig:correctness-perroom} shows that room \text{C4\_AISLE4} has an unusually low percentage of correct localizations. Our database shows that in this room \text{C7\_AISLE7} has a 15~\% probability of getting chosen.
We attribute this to a human error during training, as all the incorrectly localized scans are done within a few minutes of each other.
In short we once selected the wrong room while collecting the training data.

\section{Individual Workload (0.25 pages)}
\label{sec:individual-workload}
David:
\begin{itemize}
    \item Activity training
    \item Activity measurement window collection
    \item Computation of feature vectors
    \item Bayesian locator
    \item Offline processing of Wi-Fi measurements
    \item NSA functionality
    \item ORMLite database code
    \item SQL queries and figures generation for reports
\end{itemize}

Mark:
\begin{itemize}
    \item Activity testing
    \item k-NN classifier
    \item Wifi measurement window collection
    \item Steps counter and movement model in Bayesian locator
    \item Localization training \& testing maps
    \item General bug fixes and some reliability and performance improvements
\end{itemize}

\section{Possible Future Directions (0.25 pages)}
\label{sec:future-directions}
\subsection{Activity Monitoring}
TODO

\subsection{Localization}
Bayesian filters are not that useful if you have rooms with only a low number of visible access points.
Our trick to take the number of AP's into accounts works well when there
are not too many rooms with few visible AP's.
However, if there are more rooms like the Coffee room, this approach will likely fail.
Another possibility we contemplated was to create a bitstring of present/not-present $BSSID$'s for the current scan and the training data.
Computing the hamming distances to the training data points increases the amount of information that
is available to the filter, thus possibly increasing the accuracy.
This will more likely work in the general case.

%\clearpage
%\phantomsection
%\addcontentsline{toc}{chapter}{References}
%% styles: abbrv, ieeetr, plain
%\bibliographystyle{ieeetr}
%\bibliography{report}

\newpage
\appendix

%\input{appendix-source-code.tex}
\section{Localization Data}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.36\textwidth]{screenshot}
    \caption{GUI showing successful localization.}
    \label{fig:screenshot}
\end{figure}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.5\textwidth]{histogram}
    \caption{Histogram of two BSSID's in two adjacent aisles.}
    \label{fig:histogram}
\end{figure}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.5\textwidth]{distribution}
    \caption{Distribution of two BSSID's in two adjacent aisles.}
    \label{fig:distribution}
\end{figure}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.5\textwidth]{graph-numberAPperRoom}
    \caption{Number of access points per room.}
    \label{fig:graph-numberAPperRoom}
\end{figure}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.5\textwidth]{iterations_needed}
    \caption{Percentage of results that will eventually be correct and certain after a specific number of iterations.}
    \label{fig:iterations-needed}
\end{figure}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.5\textwidth]{correctness_perroom}
    \caption{Correct localizations per room when taking the probability of number of AP's per room into account.}
    \label{fig:correctness-perroom}
\end{figure}

\end{document}
